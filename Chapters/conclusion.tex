\chapter{ Conclusion }
\label{Conclusion}

\section{Synthèse}

Dans le chapitre \ref{DesignStudy}, nous avons étudié l'activité des agents de sécurité des  aéroports afin de fournir un outil d'exploration 3D pertinent. Grâce aux entretiens contextuels, nous avons extrait la nécessité pour le nouveau système 3D de remplacer efficacement l'ancien système bidimensionnel. Les systèmes 2D existants peuvent souffrir de 4 stratégies de dissimulation principales. Le premier est la \textbf{superposition} où une menace peut être mise à l'abri parmi les matériaux denses. Bien qu'il soit possible de voir à travers un tel «bouclier» en utilisant une pénétration élevée (puissance de rayons X améliorée) ou un traitement d'image (amélioration du contraste), ces techniques ne sont pas universellement disponibles et nécessitent également un réglage précis de nombreux paramètres, ce qui ralentit l'inspection. Deuxièmement, le \textbf{positionnement} peut être utilisé car les objets situés dans les coins, les bords ou dans le cadre du bagage sont très difficiles à repérer. Troisièmement, la \textbf{dissociation} permet de dissimuler une menace en répartissant ses parties dans le bagage, \emph{par example}, en démontant une arme et en dispersant ses parties. Enfin, un \textbf{leurre} peut être utilisé. En fait, une menace mineure (leurre) comme des petits ciseaux est clairement visible et attire l’attention de l’agent de sécurité qui peut manquer la menace réelle. Dans cet chapitre \ref{DesignStudy}, nous avons proposé un outil de visualisation interactif pour l’inspection en 3D des bagages. Ce framework offre différents types d'interaction pour effectuer une inspection virtuelle des bagages tout en traitant les problèmes d'occlusion.

Dans le chapitre \ref{lensing}, nous nous sommes concentrés sur les stratégies de gestion de l'occlusion. En effet, l'occlusion est un problème dans la visualisation volumétrique car elle empêche la visualisation directe de la région d'intérêt. Bien que de nombreuses techniques, telles que les fonctions de transfert, la segmentation de volume ou la distorsion de vue, aient été développées pour résoudre ce problème, des améliorations sont encore possibles pour mieux comprendre le voisinage des objets. Cependant, la plupart des techniques Focus+contexte existantes ne parviennent pas à résoudre une occlusion partielle dans des ensembles de données où la cible et le bloqueur sont très proches du point de vue de la densité. Pour ces raisons, nous avons proposé une nouvelle lentille focus + contextuelle répondant simultanément aux quatre exigences suivantes: Créer rapidement une vue non obstruée de la cible (R1), permettre une exploration locale flexible de la zone cible (R2), garder le contexte dans lequel la cible est incorporée visuellement (R3) et gérer les ensembles de données où la cible et les objets gênant ne peuvent pas être séparés par des manipulations de la fonction de transfert (R4).



Dans le chapitre \ref{mixedReality}, nous abordons les problèmes de rendu de volume sur les appareils mobiles (réalité virtuelle, réalité augmentée et réalité mixte). Les appareils mobiles sont de plus en plus populaires dans la société. Bien que leurs spécifications techniques puissent être totalement différentes d’un appareil à l’autre, ils deviennent tous plus puissants en termes de mémoire, de processeur, de processeur graphique et de fonctionnalités. Alors que \textbf{réalité virtuelle (VR)} immerge les utilisateurs dans un environnement numérique entièrement artificiel avec des appareils tels que HTC vive, \textbf{réalité augmentée (AR)} recouvre des objets virtuels dans un environnement réel grâce à des appareils tels que les smartphones. De plus, \textbf {réalité mixte (MR)} ne se limite pas aux superpositions, mais ancre les objets virtuels dans le monde réel afin que l'utilisateur puisse interagir avec le monde réel et l'environnement virtuel. Nous avons étudié comment fournir des outils de rendu de volume interactifs sur chacun des types de ces périphériques.


Dans cette thèse, nous présentons deux contributions principales.

\begin{itemize}

\item Tout d'abord, nous avons proposé un nouveau système de visualisation interactive pour les bagages numérisés en 3D, accéléré avec les techniques GPGPU, en fonction des besoins que nous avons extraits de l'enquête contextuelle auprès des agents de sécurité de l'aéroport.

\item Deuxièmement, nous avons proposé une nouvelle technique qui associe un rendu volumétrique basé sur du lancer de rayon à une lentille rapide, polyvalente et facile à utiliser pour prendre en charge l'exploration interactive des données occluses dans un  volume.

\end{itemize}


Nous travaillons actuellement sur un framework de rendu de volume pour des environnements de réalité mixte. En effet, nous essayons de contourner les limites de calcul grâce à des stratégies telles que le calcul à distance holographique afin de fournir de nouvelles interactions rapides.

De plus, nous prévoyons d’adapter notre framework pour visualiser des scans animés. Visualiser le même jeu de données à des états différents dans le temps peut offrir de nombreux avantages pour faciliter l'exploration des données. Les potentiels pour une telle visualisation peuvent être les suivants. Tout d’abord, sachant que le mouvement transmet des informations, l’animation 3D a une qualité supérieure. L'utilisation de cette technique pour visualiser les fluides peut être très utile. Aussi, pour un visuel
 attrayant, l'animation 3D est beaucoup plus réaliste. En effet, un fluide en mouvement ou un cœur battant est plus réaliste et
 attrayant qu'un scan statique. Cependant, avec une telle visualisation, de nombreux algorithmes d’optimisation doivent être utilisés pour
     permettre l'interactivité avec différents états des mêmes jeux de données en même temps.

\NewPage


As seen in the previous chapters, the visualizations of volumetric datasets are not so trivial. These visualizations are used in various type of field such as medicine, physics, biology, archaeology, etc. These visualizations face different types of difficulties and challenges according to the application domain. For instance in art, the most important challenge is the beauty of the generated image while in most other application domains, the frame rate is also important.

 
In \autoref{DesignStudy}, we studied the activity of the airport security agents in order to provide a relevant 3D exploration tool. Thanks to contextual interviews, we extracted the requirement for the new 3D system to replace efficiently the old 2-dimensional system. The existing 2D systems can suffer from 4 main dissimulation strategies. The first one is the \textbf{superposition} where a threat may be sheltered among dense materials. While possible to see through such a 'shield' using high penetration (enhanced X-ray power) or image processing (contrast improvement), such techniques are not universally available and also require fine-tuning many parameters, which slows down inspection. Second, the \textbf{location} can be used since objects located in the corners, edges, or in the luggage's frame are very hard to spot. Third, the \textbf{dissociation} allows concealing a threat by spreading its parts in the luggage, \emph{e.g}, by disassembling a weapon and scattering its parts. Finally, a \textbf{lure} can be used. In fact, A minor threat (lure) like small scissors is clearly visible and catch the security agent's attention who can miss the real threat. In this \autoref{DesignStudy}, we proposed an interactive visualization tool for 3D baggage inspection. This framework offers different types of interaction to perform a virtual inspection of baggage while dealing with occlusion issues.



In \autoref{lensing} we focused on occlusion management strategies. In fact, occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we proposed a novel focus+context lens that fulfills simultaneously the four following requirements: Rapidly create an unobstructed view of the target (R1), allow a flexible local exploration of the target zone (R2), keep the context in which the target is visually embedded (R3), and handle datasets where the target and occluders cannot  be separated by transfer function manipulations (R4).



In \autoref{mixedReality}, we address the volume rendering challenges on mobile devices (Virtual reality, augmented reality, and mixed reality). Mobile devices are getting more and more popular across the population. Although their technical specifications can be totally different from one device to another, they are all becoming more powerful in terms of memory, CPU, GPU, and features. While \textbf{Virtual reality (VR)} immerses users in a fully artificial digital environment with devices such us HTC vive, \textbf {Augmented reality (AR)} overlays virtual objects on the real-world environment thanks to devices such as smartphones. In addition, \textbf {Mixed reality (MR)} not just overlays but anchors virtual objects to the real world so the user can interact with both the real world and the virtual environment. We studied how to provide interactive volume rendering tools on each type of these devices.



In this thesis, we present two main contributions.  

\begin{itemize}

\item First, we proposed a new interactive visualization system for 3D scanned baggage accelerated with GPGPU techniques in accordance with the needs we extracted from the contextual inquiry with the airport security agents. 

\item Secondly, we proposed a novel technique which combines high-quality DVR with a fast, versatile, and easy to use, lens to support the interactive exploration of occluded data in volumes.

\end{itemize}



\section{summary} 

\subsection{ Design Study: Interactive exploration of 3D scanned baggage } 

During this thesis, I had the opportunity to intend to training courses for security agents' instructors, and to visit an airport (Toulouse-Blagnac Airport). These helped me to study the activity of security agents and get the users' needs. From these contextual interviews, we noticed the 4 main concealment strategies (superposition, location, dissociation, lure).  

We propose a set of interaction accelerated by GPGPU computing, especially with the Nvidia's CUDA API. The first interaction was the transfer function edition. Since airport security agents have a reduced time frame and limited knowledge of technical constraints, we defined six TF presets (\autoref{f:preset}). These presets only modify the TF transparency curve while keeping the same color mapping. Secondly, we dealt with objects selection and investigation. In order to investigate in detail a specific object, we offered the possibility to interactively isolate it, remove surrounding items to address occlusion issues, or find a suitable point of view. For instance,
the magic brushing removes all voxels with a lower density than the first one encountered at the beginning of the brushing process. This technique helps the user to directly define the densities he or she wants to brush. In addition, it avoids multiple interactions with the histogram and its range slider to define the range of brushable densities.


We have proposed a 3D scanned baggage visualization framework to simplify the detection of threats and prohibited objects. This system was developed in close collaboration with airport security agents, which allowed regular feedback from potential users of this system.
First, we can highlight the overall positive feedback from security agents who had the opportunity to test our system. The latter emphasized the simplicity of basic interactions (rotations, choice of density levels, selections, deletions). In addition, they showed an interest in the operation of the different filters applicable by our system.

The tools we offer allow security agents to conduct a virtual search of baggage deemed suspicious. However, given the heterogeneity of scanners, developed interactions require some adjustments to our system depending on the machine used to scan the baggage. In fact, tomographs differ in many aspects depending on the manufacturer: the resolution, the type of data, the sensitivity to noise, the endianness.

Moreover, given the infinity of the possibilities of the components of a piece of luggage, it is very difficult to claim to have a robust cable segmentation algorithm to precisely dissociate the different objects inside the baggage. That's why we have provided several easy-to-use tools so that we can quickly explore any type of baggage.


The evaluation was based only on qualitative feedback from the security agents; which represents a weakness of this study, and therefore a possible improvement.

\par The purpose of this study on 3D scanned baggage was to propose a set of interactions to facilitate the exploration of this baggage. However, we have not sufficiently addressed the optimization of baggage inspection time. As a reminder, the execution and decision time of airport security officers has a strong impact on economic issues.

In addition, it is imperative to propose new 3D scanned baggage inspection protocols. Indeed, protocols already exist for 2D imaging, and are taught to security agents during their training as they are still working mostly with older systems (2D flat image). In this case, security agents are trained to quickly detect anomalies on luggage scanned in 2D, which is not yet the case for 3D imaging. For the moment, a tool such as the one proposed, would work perfectly in symbiosis with an automatic system that would allow sorting to identify previously non-compliant baggage. Then our tools can be a good solution to further investigate a potential threat with more available time.



\subsection{Interactive obstruction-free lensing for volumetric data visualization }
In this part of the thesis, we presented a new fish-eye-like context-and-focus lens that addresses the occlusion problems inherent in scalar volume rendering. The interactive lens that we propose consists mainly of two major steps. The first step is to converge the rays towards the axis of the lens so as to avoid obstacles in the area. The second step consists in scattering (fanning out) rays to best sample the target of interest.The main weakness of this lens is the fact that it requires to find beforehand an interesting angle of view to explore an area of the dataset. This lens also responds to the need to potentially circumvent the weaknesses of the data segmentations while keeping a global context (out of the lens). The use of our lens offers the possibility to modify several parameters inside it. This is the lighting, the direction of the gaze, transparency, and so on. These parameters make it possible to better dissociate the inside of the lens from its outside. However, it is not trivial to propose simple interactions with a weak learning allowing to easily modify all these parameters. Because our framework is based on an accelerated raycasting through the CUDA GPGPU programming language, it is currently optimized for Nvidia graphics cards and can only work on them. The use of more free GPGPU languages such as OpenCL would be a notable addition to the portability and genericity of the current implementations of this algorithm. In addition, It is important to emphasize that graphics accelerations are heavily dependent on the hardware.

Several possibilities for improvement are possible following this study. Given the large number of parameters that affect the function of the lens as well as its geometric properties (depth of focus, lens radius, interpolation between focus and external context, etc.), it would be interesting to to obtain a heuristic allowing to have interesting parameters in each case of uses. This would save time when exploring datasets with this technique. 

Moreover, our lens could be extended to different types of volumetric data-sets, such as multivariate (vector, tensor) fields.

Finally, since this study has not been evaluated in depth compared to existing systems, it would be interesting to conduct this comparative study to better position our work compared to what is currently done


\section{Perspective and future work}

Further evaluation should be carried out to strengthen our contributions during this thesis. In fact, we can elaborate on different evaluation protocols to assess our hypothesis and first observations about our 3D visualization framework. The first evaluation protocol can assess whether a virtual exploration of baggage is less dangerous than a real physical search. In addition, we could measure the speed of each type of security search (virtual and physical) in order to determine exactly which one can increase effectively and efficiently the number passengers checked. Secondly, we can perform an extensive evaluation of the learning effect, the eventual perceptive bias, and their impact on the decision-making process.  It can also help to identify more weaknesses of our propositions in order to correct them. 

Moreover, we can adapt our framework to the training of the airport security agents. Taking into account the remarks of the security agents instructors, we can add or modify some tools in order to provide more information and details on the densities, the weight, the real size, etc.  


We are currently working on a  volume rendering framework on mixed reality environments.  In fact, we are trying to bypass the computational limitations thanks to strategies like holographic remoting in order to provide fast novel interactions. 


In addition,  we can incorporate new technologies support into our framework. For example, haptic feedbacks our eye tracking may enhance the perception of the information embedded into the volumetric data-sets. In fact, a haptic device recreates the sense of touch by applying forces, vibrations, or motions to the user, and the eye-tracker can take advantage of the user's gaze. For instance, an eye-tracker can ensure that the security agent has checked all the areas of the baggage. 


Furthermore, our framework can help to do data-driven storytelling. In fact, our tools can be oriented in order to communicate the user's insights effectively, giving the data a voice, see \cite{storytelling}.

Furthermore, we plan to adapt our framework to visualize animated CT scans. Displaying the same data-set with different state evolving overtime can offer many advantages in order to ease the data exploration. The potential benefits for such visualization can be the following. First, as motion communicates, 3D animation has a superior ability to portray movement. Using these techniques to visualize fluids can be highly valuable. Also, for visual appeal, 3D animation is much more realistic. In fact, a moving fluid or a beating heart is more realistic and appealing than a static CT scan. However, with such visualization, many optimization algorithms must be used to
     allow the interactivity with different states of the same data-sets at the same time.
     