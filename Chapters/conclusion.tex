\chapter{ Conclusion }
\label{Conclusion}

\section{Synthèse}

Dans le chapitre \ref{DesignStudy}, nous avons étudié l'activité des agents de sécurité des  aéroports afin de fournir un outil d'exploration 3D pertinent. Grâce aux entretiens contextuels, nous avons extrait la nécessité pour le nouveau système 3D de remplacer efficacement l'ancien système bidimensionnel. Les systèmes 2D existants peuvent souffrir de 4 stratégies de dissimulation principales. Le premier est la \textbf{superposition} où une menace peut être mise à l'abri parmi les matériaux denses. Bien qu'il soit possible de voir à travers un tel «bouclier» en utilisant une pénétration élevée (puissance de rayons X améliorée) ou un traitement d'image (amélioration du contraste), ces techniques ne sont pas universellement disponibles et nécessitent également un réglage précis de nombreux paramètres, ce qui ralentit l'inspection. Deuxièmement, le \textbf{positionnement} peut être utilisé car les objets situés dans les coins, les bords ou dans le cadre du bagage sont très difficiles à repérer. Troisièmement, la \textbf{dissociation} permet de dissimuler une menace en répartissant ses parties dans le bagage, \emph{par example}, en démontant une arme et en dispersant ses parties. Enfin, un \textbf{leurre} peut être utilisé. En fait, une menace mineure (leurre) comme des petits ciseaux est clairement visible et attire l’attention de l’agent de sécurité qui peut manquer la menace réelle. Dans cet chapitre \ref{DesignStudy}, nous avons proposé un outil de visualisation interactif pour l’inspection en 3D des bagages. Ce framework offre différents types d'interaction pour effectuer une inspection virtuelle des bagages tout en traitant les problèmes d'occlusion.

Dans le chapitre \ref{lensing}, nous nous sommes concentrés sur les stratégies de gestion de l'occlusion. En effet, l'occlusion est un problème dans la visualisation volumétrique car elle empêche la visualisation directe de la région d'intérêt. Bien que de nombreuses techniques, telles que les fonctions de transfert, la segmentation de volume ou la distorsion de vue, aient été développées pour résoudre ce problème, des améliorations sont encore possibles pour mieux comprendre le voisinage des objets. Cependant, la plupart des techniques Focus+contexte existantes ne parviennent pas à résoudre une occlusion partielle dans des ensembles de données où la cible et le bloqueur sont très proches du point de vue de la densité. Pour ces raisons, nous avons proposé une nouvelle lentille focus + contextuelle répondant simultanément aux quatre exigences suivantes: Créer rapidement une vue non obstruée de la cible (R1), permettre une exploration locale flexible de la zone cible (R2), garder le contexte dans lequel la cible est incorporée visuellement (R3) et gérer les ensembles de données où la cible et les objets gênant ne peuvent pas être séparés par des manipulations de la fonction de transfert (R4).



Dans le chapitre \ref{mixedReality}, nous abordons les problèmes de rendu de volume sur les appareils mobiles (réalité virtuelle, réalité augmentée et réalité mixte). Les appareils mobiles sont de plus en plus populaires dans la société. Bien que leurs spécifications techniques puissent être totalement différentes d’un appareil à l’autre, ils deviennent tous plus puissants en termes de mémoire, de processeur, de processeur graphique et de fonctionnalités. Alors que \textbf{réalité virtuelle (VR)} immerge les utilisateurs dans un environnement numérique entièrement artificiel avec des appareils tels que HTC vive, \textbf{réalité augmentée (AR)} recouvre des objets virtuels dans un environnement réel grâce à des appareils tels que les smartphones. De plus, \textbf {réalité mixte (MR)} ne se limite pas aux superpositions, mais ancre les objets virtuels dans le monde réel afin que l'utilisateur puisse interagir avec le monde réel et l'environnement virtuel. Nous avons étudié comment fournir des outils de rendu de volume interactifs sur chacun des types de ces périphériques.


Dans cette thèse, nous présentons deux contributions principales.

\begin{itemize}

\item Tout d'abord, nous avons proposé un nouveau système de visualisation interactive pour les bagages numérisés en 3D, accéléré avec les techniques GPGPU, en fonction des besoins que nous avons extraits de l'enquête contextuelle auprès des agents de sécurité de l'aéroport.

\item Deuxièmement, nous avons proposé une nouvelle technique qui associe un rendu volumétrique basé sur du lancer de rayon à une lentille rapide, polyvalente et facile à utiliser pour prendre en charge l'exploration interactive des données occluses dans un  volume.

\end{itemize}


Nous travaillons actuellement sur un framework de rendu de volume pour des environnements de réalité mixte. En effet, nous essayons de contourner les limites de calcul grâce à des stratégies telles que le calcul à distance holographique afin de fournir de nouvelles interactions rapides.

De plus, nous prévoyons d’adapter notre framework pour visualiser des scans animés. Visualiser le même jeu de données à des états différents dans le temps peut offrir de nombreux avantages pour faciliter l'exploration des données. Les potentiels pour une telle visualisation peuvent être les suivants. Tout d’abord, sachant que le mouvement transmet des informations, l’animation 3D a une qualité supérieure. L'utilisation de cette technique pour visualiser les fluides peut être très utile. Aussi, pour un visuel
 attrayant, l'animation 3D est beaucoup plus réaliste. En effet, un fluide en mouvement ou un cœur battant est plus réaliste et
 attrayant qu'un scan statique. Cependant, avec une telle visualisation, de nombreux algorithmes d’optimisation doivent être utilisés pour
     permettre l'interactivité avec différents états des mêmes jeux de données en même temps.

\NewPage


As seen in the previous chapters, the visualizations of volumetric datasets are not so trivial. These visualizations are used in various type of field such as medicine, physics, biology, archaeology, etc. These visualizations face different types of difficulties and challenges according to the application domain. For instance in art, the most important challenge is the beauty of the generated image while in most other application domains, the frame rate is also important.

 
In \autoref{DesignStudy}, we studied the activity of the airport security agents in order to provide a relevant 3D exploration tool. Thanks to contextual interviews, we extracted the requirement for the new 3D system to replace efficiently the old 2-dimensional system. The existing 2D systems can suffer from 4 main dissimulation strategies. The first one is the \textbf{superposition} where a threat may be sheltered among dense materials. While possible to see through such a 'shield' using high penetration (enhanced X-ray power) or image processing (contrast improvement), such techniques are not universally available and also require fine-tuning many parameters, which slows down inspection. Second, the \textbf{location} can be used since objects located in the corners, edges, or in the luggage's frame are very hard to spot. Third, the \textbf{dissociation} allows concealing a threat by spreading its parts in the luggage, \emph{e.g}, by disassembling a weapon and scattering its parts. Finally, a \textbf{lure} can be used. In fact, A minor threat (lure) like small scissors is clearly visible and catch the security agent's attention who can miss the real threat. In this \autoref{DesignStudy}, we proposed an interactive visualization tool for 3D baggage inspection. This framework offers different types of interaction to perform a virtual inspection of baggage while dealing with occlusion issues.



In \autoref{lensing} we focused on occlusion management strategies. In fact, occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we proposed a novel focus+context lens that fulfills simultaneously the four following requirements: Rapidly create an unobstructed view of the target (R1), allow a flexible local exploration of the target zone (R2), keep the context in which the target is visually embedded (R3), and handle datasets where the target and occluders cannot  be separated by transfer function manipulations (R4).



In \autoref{mixedReality}, we address the volume rendering challenges on mobile devices (Virtual reality, augmented reality, and mixed reality). Mobile devices are getting more and more popular across the population. Although their technical specifications can be totally different from one device to another, they are all becoming more powerful in terms of memory, CPU, GPU, and features. While \textbf{Virtual reality (VR)} immerses users in a fully artificial digital environment with devices such us HTC vive, \textbf {Augmented reality (AR)} overlays virtual objects on the real-world environment thanks to devices such as smartphones. In addition, \textbf {Mixed reality (MR)} not just overlays but anchors virtual objects to the real world so the user can interact with both the real world and the virtual environment. We studied how to provide interactive volume rendering tools on each type of these devices.



In this thesis, we present two main contributions.  

\begin{itemize}

\item First, we proposed a new interactive visualization system for 3D scanned baggage accelerated with GPGPU techniques in accordance with the needs we extracted from the contextual inquiry with the airport security agents. 

\item Secondly, we proposed a novel technique which combines high-quality DVR with a fast, versatile, and easy to use, lens to support the interactive exploration of occluded data in volumes.

\end{itemize}



\section{summary} 

\subsection{ Design Study: Interactive exploration of 3D scanned baggage } 

During this thesis, I had the opportunity to intend to training courses for security agents' instructors, and to visit an airport (Toulouse-Blagnac Airport). These helped me to study the activity of security agents and get the users' needs. From these contextual interviews, we noticed the 4 main concealment strategies (superposition, location, dissociation, lure).  

We propose a set of interaction accelerated by GPGPU computing, especially with the Nvidia's CUDA API. The first interaction was the transfer function edition. Since airport security agents have a reduced time frame and limited knowledge of technical constraints, we defined six TF presets (\autoref{f:preset}). These presets only modify the TF transparency curve while keeping the same color mapping. Secondly, we dealt with objects selection and investigation. In order to investigate in detail a specific object, we offered the possibility to interactively isolate it, remove surrounding items to address occlusion issues, or find a suitable point of view. For instance,
the magic brushing removes all voxels with a lower density than the first one encountered at the beginning of the brushing process. This technique helps the user to directly define the densities he or she wants to brush. This technique avoids multiple interactions with the histogram and its range slider to define the range of brushable densities.


Since we developed this system with four baggage security practitioners, we had the opportunity to validate the usefulness of each proposed technique. Through an interactive process, the users gave their feedback all along the development process which helped to assess and to guide the proposed interaction techniques. Feedback was mainly positive and the user did not face any specific difficulty to use our system. Users mainly appreciated the simple interface with few widgets and the reduced set of interactions. Surprisingly, the security agents instructors were very interested to use the transfer function. The histogram and its transfer function were also appreciated even if the corresponding technique is not simple to understand. We suppose that our interface motivates users to learn more regarding the technique behind it. The users also mentioned the need to display the actual density (the numerical value) of the selected object. They also ask many times if the displayed color corresponds to the one currently in use in operational settings. This confirms the fact that users are willing to keep some existing features and prefer to use a system they are already familiar with.
The users also appreciated our design requirements with smooth transitions and incremental investigations of baggage.
\par All of these observations and qualitative evaluations deserve to be validated through proper evaluations which are out of the scope of this design study .
Our system is fully functional and interactive enough to perform baggage explorations. Many improvements can still be done in order to improve its usages in terms of new interactions and exploration time reductions.
Technically speaking, the selection of the adequate point of view can be improved with more investigated faces. But in practice, this simple paradigm remains suitable. If the computed point of view is not fully satisfactory, one can manually rotate the baggage. Nevertheless, the developed algorithm will not necessarily provide the best solution (the lowest occlusion) but a satisfactory one.
\par Our goal was to develop innovative interactions to support baggage exploration but we did not really take into account the optimization of the exploration duration time. Manipulating the 3D volume may take time as well as our new interaction techniques. We think that these techniques have a great potential but they are suitable to explore in more details a suspicious baggage. Existing investigation techniques (with the 2D flattened image) are suitable to quickly and efficiently detect ''clean'' baggage. Then our tools can be a good solution to further investigate a potential threat with more available time.



\subsection{Interactive obstruction-free lensing for volumetric data visualization }
In this part of the thesis, we presented a new fish-eye-like context-and-focus lens that addresses the occlusion problems inherent in scalar volume rendering. The principle of our lens consists in first gathering (squeezing) rays so that they easily pass through occluding densities (given a user-specified opacity transfer function) and next scattering (fanning out) rays to best sample the target of interest. Our lens can be directly applied to any DVR raycaster and scalar volume data-set. Its main constraint is that the user should be able to find a viewpoint from which the target of interest, deep buried in the data, is at least slightly visible. We also present several modifications of the local rendering parameters within the lens (view direction, lighting parameters, opacity transfer function) that aim to both better separate the focus (lens) from the context (volume) and also allow more detailed examining of the target. Our lens is easy to use -- all its parameters are controlled via direct mouse-and-keyboard interaction -- and can be efficiently implemented atop of a standard GPU raycaster. Our lens is especially useful for highlighting structures of interest which are both deeply embedded in volumetric data and cannot be revealed by standard transfer function manipulations due to similar densities in the occluders and target. We demonstrate these points using five use-cases involving data-sets from baggage detection, fluid visualization, air traffic control, and chest radiology, and DTI fiber tracts.

Several improvements to our proposal are possible, as follows. First and foremost, heuristics can be sought to link all our free parameters (lens size, focus depth, interpolation between focus and context) directly to the volume data, so the user interaction is minimized and therefore exploration efficiency is increased. Secondly, our lens could be extended to different types of volumetric data-sets, such as multivariate (vector, tensor) fields. Last but not least, a formal wider-scale evaluation of how the lens addresses more specific tasks, and how it compares to existing tools for these tasks, such as other lens types, is a goal we aim to pursue next.

\section{Perspective and future work}

Further evaluation should be carried out to strengthen our contributions during this thesis. In fact, we can elaborate different evaluation protocols to assess our hypothesis and first observations about our 3D visualization framework. The first evaluation protocol can assess whether a virtual exploration of baggage is less dangerous than a real physical search. In addition, we could measure the speed of each type of security search (virtual and physical) in order to determine exactly which one can increase effectively and efficiently the number passengers checked. Secondly, we can perform an extensive evaluation of the learning effect, the eventual perceptive bias, and their impact on the decision-making process.  It can also help to identify more weaknesses of our propositions in order to correct them. 

Moreover, we can adapt our framework to the training of the airport security agents. Taking into account the remarks of the security agents instructors, we can add or modify some tools in order to provide more information and details on the densities, the weight, the real size, etc.  


We are currently working on a  volume rendering framework on mixed reality environments.  In fact, we are trying to bypass the computational limitations thanks to strategies like holographic remoting in order to provide fast novel interactions. 


In addition,  we can incorporate new technologies support into our framework. For example, haptic feedbacks our eye tracking may enhance the perception of the information embedded into the volumetric data-sets. In fact, a haptic device recreates the sense of touch by applying forces, vibrations, or motions to the user, and the eye-tracker can take advantage of the user's gaze. For instance, an eye-tracker can ensure that the security agent has checked all the areas of the baggage. 


Futhermore, our framework can help to do data-driven storytelling. In fact, our tools can be oriented in order to communicate the user's insights effectively, giving the data a voice, see \cite{storytelling}.

Furthermore, we plan to adapt our framework to visualize animated CT scans. Displaying the same data-set with
 different state evolving overtime can offer many advantages in order to ease the data exploration. The potential
 benefits for such visualization can be the following. First, as motion communicates, 3D animation has a superior 
 ability to portray movement. Using these technique to visualize fluids can be highly valuable. Also, for visual
 appeal, 3D animation is much more realistic. In fact, a moving fluid or a beating heart is more realistic and
 appealing than a static CT scan. However with such visualization, many optimization algorithms must be used to
     allow the interactivity with different states of the same data-sets at the same time.
     

     