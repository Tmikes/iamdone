\chapter{ Conclusion }
\label{Conclusion}

As seen in the previous chapters, the visualizations of volumetric datasets are not so trivial. These visualizations are used in various type of field such us medicine, physics, biology, archaeology, etc. These visualizations face different types of difficulties and challenges according to the application domain. For instance in art, the most important challenge is the beauty of the generated image while in most other application domains, the frame rate is also important.

 
In \autoref{DesignStudy}, we studied the activity of the airport security agents in order to provide a relevant 3D exploration tool. Thanks to contextual interviews, we extracted the requirement for the new 3D system  to replace efficiently  the old 2 dimensional system. The existing 2d systems can suffer from 4 main dissimulation strategies. The first one is the \textbf{superposition} where a threat may be sheltered among dense materials. While possible to see through such a 'shield' using high penetration (enhanced X-ray power) or image processing (contrast improvement), such techniques are not universally available and also require fine-tuning many parameters, which slows down inspection. Second, the \textbf{location} can be used since objects located in the corners, edges, or in the luggage's frame are very hard to spot. Third, the \textbf{dissociation} allows to conceal a threat by spreading its parts in the luggage, \emph{e.g}, by disassembling a weapon and scattering its parts. Finally, a \textbf{lure} can be used. In fact A minor threat (lure) like small scissors is clearly visible and catch the security agent's attention who can miss the real threat. In this \autoref{DesignStudy}, we proposed an interactive visualization tool for 3D baggage inspection. This framework offers different types of interaction to perform a virtual inspection of baggage while dealing with occlusion issues.


In \autoref{lensing}, 

interviews reported in Chapter 3 show that GIS experts often need to relate and compare
different geographic layers. Non expert users need to work with multiple layers
too, in casual tasks like planning a hike, or exploring the evolution of some familiar
location. Existing techniques to combine multiple layers, however, remain limited.
They are often limited to toggling between layers, swiping between them and sometimes
drilling through them. They do not take advantage of the information semantics
to create more interactive transitions to better support users in their tasks.
This thesis addresses the problem of relating different geographical representations
of the same region at the same scale through interactive transitions. Transitions
can be based on spatial multiplexing (i.e., combining different representations spatially
through map composition) or on time multiplexing (i.e., sequencing the representations
using smooth animations).
We present three contributions. First, we describe a characterization and an
evaluation of interactive map comparison techniques based on spatial multiplexing.
Then, we introduce MapMosaic, a novel approach for spatial multiplexing. Finally,
we present Baia a novel approach for time multiplexing to better convey changes
between before-and-after satellite images. We give a short summary of each contribution
below, and then open directions for future work.


Since we developed this system with four baggage security practitioners, we had the opportunity to validate the usefulness of each developed technique. Through an interactive process, the users gave their feedbacks all along the development process which helped to assess and to guide the proposed interaction techniques. Feedback was mainly positive and the user did not face any specific difficulty to use our system. Users mainly appreciated the simple interface with few widgets and the reduced set of interactions. Surprisingly, users were very interested to use the transfer function. The histogram and its transfer function were also appreciated even if the corresponding technique is not simple to understand. We suppose that our interface motivates users to learn more regarding the technique behind it. Users also mentioned the need to display the actual density (the numerical value) of selected object. They also ask many times if the displayed color corresponds to the one currently in use in operational settings. This confirms the fact that users are willing to keep some existing features and prefer to use a system they are already familiar with.
The users also appreciated our design requirements with smooth transitions and incremental investigations of baggage.
\par All of these observations and qualitative evaluations deserve to be validated through proper evaluations which are out of the scope of this design study paper.
Our system is fully functional and interactive enough to perform baggage explorations. Many improvements can still be done in order to improve its usages in terms of new interactions and exploration time reductions.
Technically speaking, the selection of the adequate point of view can be improved with more than 6 investigated faces. But in practice, this simple paradigm remains suitable. If the computed point of view is not fully satisfactory, one can manual rotate the baggage. Nevertheless, the developed algorithm will not necessary provide the best solution (the lowest occlusion) but a satisfactory one.
\par Our goal was to develop
innovative interactions to support baggage exploration but we did not really took into account the optimization of the exploration duration time. Manipulating the 3D volume may take time as well as our new interaction techniques. We think that these techniques have a great potential but they are suitable to explore in more details a suspicious baggage. Existing investigation techniques (with the 2D flattened image) are suitable to quickly and efficiently detect ''clean'' baggage. Then our tools can be a good solution to further investigate a potential threat with more available time.


In this chapter, we presented a new fish-eye-like context-and-focus lens that addresses the occlusion problems inherent in scalar volume rendering. The principle of our lens consists in first gathering (squeezing) rays so that they easily pass through occluding densities (given a user-specified opacity transfer function) and next scattering (fanning out) rays to best sample the target of interest. Our lens can be directly applied to any DVR raycaster and scalar volume dataset. Its main constraint is that the user should be able to find a viewpoint from which the target of interest, deep buried in the data, is at least slightly visible. We also present several modifications of the local rendering parameters within the lens (view direction, lighting parameters, opacity transfer function) that aim to both better separate the focus (lens) from the context (volume) and also allow more detailed examining of the target. Our lens is easy to use -- all its parameters are controlled via direct mouse-and-keyboard interaction -- and can be efficiently implemented atop of a standard GPU ray caster. Our lens is especially useful for highlighting structures of interest which are both deeply embedded in volumetric data and cannot be revealed by standard transfer function manipulations due to similar densities in the occluders and target. We demonstrate these points using five use-cases involving datasets from baggage detection, fluid visualization, air traffic control, and chest radiology, and DTI fiber tracts.

Several improvements to our proposal are possible, as follows. First and foremost, heuristics can be sought to link all our free parameters (lens size, focus depth, interpolation between focus and context) directly to the volume data, so the user interaction is minimized and therefore exploration efficiency is increased. Secondly, our lens could be extended to different types of volumetric datasets, such as multivariate (vector, tensor) fields. Last but not least, a formal wider-scale evaluation of how the lens addresses more specific tasks, and how it compares to existing tools for these tasks, such as other lens types, is a goal we aim to pursue next.